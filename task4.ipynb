{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-07T13:25:01.218718Z",
     "start_time": "2024-12-07T13:25:01.208955Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.impute._iterative import IterativeImputer\n",
    "from sklearn.manifold import Isomap\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import missingno as msno\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T13:40:41.326279Z",
     "start_time": "2024-12-07T13:40:41.315962Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def cross_val_cMSE(pipeline, X, y, c, cv=5):\n",
    "    scores = []\n",
    "    fold_size = len(X) // cv\n",
    "\n",
    "    for i in range(cv):\n",
    "        X_val = X[i * fold_size:(i + 1) * fold_size]\n",
    "        y_val = y[i * fold_size:(i + 1) * fold_size]\n",
    "        c_val = c[i * fold_size:(i + 1) * fold_size]\n",
    "\n",
    "        X_train = np.concatenate((X[:i * fold_size], X[(i + 1) * fold_size:]))\n",
    "        y_train = np.concatenate((y[:i * fold_size], y[(i + 1) * fold_size:]))\n",
    "\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        y_val_pred = pipeline.predict(X_val)\n",
    "        scores.append(cMSE(y_val_pred, y_val, c_val))\n",
    "\n",
    "    return scores"
   ],
   "id": "9da9f2705d094fe5",
   "outputs": [],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T11:42:56.113201Z",
     "start_time": "2024-12-07T11:42:56.106720Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def cMSE(y_hat, y, c):\n",
    "    err = y - y_hat\n",
    "    loss = (1 - c) * err ** 2 + c * np.maximum(0, err) ** 2\n",
    "    return np.sum(loss) / len(y)"
   ],
   "id": "2e40ec2aca2b4b63",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T11:42:58.135428Z",
     "start_time": "2024-12-07T11:42:58.122310Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class FrozenTransformer(BaseEstimator):\n",
    "    def __init__(self, fitted_transformer):\n",
    "        self.fitted_transformer = fitted_transformer\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        # `fitted_transformer`'s attributes are now accessible\n",
    "        return getattr(self.fitted_transformer, name)\n",
    "\n",
    "    def __sklearn_clone__(self):\n",
    "        return self\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Fitting does not change the state of the estimator\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        # transform only transforms the data\n",
    "        return self.fitted_transformer.transform(X)\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        # fit_transform only transforms the data\n",
    "        return self.fitted_transformer.transform(X)"
   ],
   "id": "fe580caf573cac5",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T13:33:25.849731Z",
     "start_time": "2024-12-07T13:33:25.839308Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class GradientDescentRegressor(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, lr=0.01, epochs=1000, lambda_reg=0, lasso=False):\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.lambda_reg = lambda_reg\n",
    "        self.lasso = lasso\n",
    "        self.coef_ = None\n",
    "        self.intercept_ = 0\n",
    "\n",
    "    def fit(self, X, y, c):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.coef_ = np.zeros(n_features)\n",
    "        self.intercept_ = 0\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            # Predictions\n",
    "            y_hat = np.dot(X, self.coef_) + self.intercept_\n",
    "\n",
    "            # Gradient\n",
    "            error = y - y_hat\n",
    "            grad = -2 * ((1 - c) * error + c * np.maximum(0, error))\n",
    "            \n",
    "            # Weights/Bias\n",
    "            coef_grad = np.dot(X.T, grad) / n_samples\n",
    "            intercept_grad = np.sum(grad) / n_samples\n",
    "\n",
    "            # Lasso / Ridge\n",
    "            if self.lasso:\n",
    "                coef_grad += self.lambda_reg * np.sign(self.coef_)\n",
    "            else:  # Ridge\n",
    "                coef_grad += self.lambda_reg * self.coef_\n",
    "\n",
    "            # Update weights\n",
    "            self.coef_ -= self.lr * coef_grad\n",
    "            self.intercept_ -= self.lr * intercept_grad\n",
    "\n",
    "            # Compute loss every 100 epochs for tracking\n",
    "            #if epoch % 100 == 0:\n",
    "                #loss = cMSE(y_hat, y, c)\n",
    "                #print(f\"Epoch {epoch}: cMSE Loss = {loss:.4f}\")\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.dot(X, self.coef_) + self.intercept_"
   ],
   "id": "86d836c4ccb21d89",
   "outputs": [],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T11:43:00.719597Z",
     "start_time": "2024-12-07T11:43:00.702717Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def apply_imputation(df, column, strategy='mean'):\n",
    "    if strategy == 'mean':\n",
    "        imputer = SimpleImputer(strategy='mean')\n",
    "    elif strategy == 'median':\n",
    "        imputer = SimpleImputer(strategy='median')\n",
    "    elif strategy == 'most_frequent':\n",
    "        imputer = SimpleImputer(strategy='most_frequent')\n",
    "    elif strategy == 'knn':\n",
    "        imputer = KNNImputer(n_neighbors=5)\n",
    "    elif strategy == 'iterative':\n",
    "        imputer = IterativeImputer(max_iter=10, random_state=60)\n",
    "\n",
    "    #print(df[column])\n",
    "    df[column] = imputer.fit_transform(df[[column]])\n",
    "    #print(df[column])\n",
    "    return df"
   ],
   "id": "29fd313e14f98e28",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Data with Labels:\n",
    "\n",
    "This is the subset of the dataset **where the target variable(s) are not missing**.\n",
    "Neste caso, data with labels são todas as rows em que o SurvivalTime não é NaN.\n",
    "\n",
    "### Data without Labels:\n",
    "\n",
    "This is the subset of the dataset **where the target variable(s) are missing**.\n",
    "Neste caso, data without labels são todas as rows em que o SurvivalTime é NaN."
   ],
   "id": "6d656a56feb282aa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T13:19:55.866568Z",
     "start_time": "2024-12-07T13:19:55.853114Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process_data_with_labels(strategy):\n",
    "    train_path = './Datasets/train_data.csv'\n",
    "    test_path = \"./Datasets/test_data.csv\"\n",
    "\n",
    "    df_train_clean = pd.read_csv(train_path)\n",
    "    df_test_filled = pd.read_csv(test_path)\n",
    "\n",
    "    df_train_clean = df_train_clean.dropna(subset=['SurvivalTime']).copy()\n",
    "    #print(\"Antes da imputation\")\n",
    "    #msno.bar(df_train_clean)\n",
    "\n",
    "    #agora temos que aplicar a imputation às features com missing values\n",
    "    df_train_clean = apply_imputation(df_train_clean, 'GeneticRisk', strategy)\n",
    "    df_train_clean = apply_imputation(df_train_clean, 'ComorbidityIndex', strategy)\n",
    "    df_train_clean = apply_imputation(df_train_clean, 'TreatmentResponse', strategy)\n",
    "\n",
    "    df_test_filled = apply_imputation(df_test_filled, 'GeneticRisk', strategy)\n",
    "    df_test_filled = apply_imputation(df_test_filled, 'ComorbidityIndex', strategy)\n",
    "    df_test_filled = apply_imputation(df_test_filled, 'TreatmentResponse', strategy)\n",
    "\n",
    "    #print(\"Depois da imputation\")\n",
    "    #msno.bar(df_train_clean)\n",
    "\n",
    "    df_test_filled.drop('Id', axis=1, inplace=True)\n",
    "    df_test_filled = df_test_filled.drop(columns=['Gender', 'GeneticRisk'])\n",
    "\n",
    "    df_train_clean = df_train_clean[df_train_clean['Censored'] == 0]\n",
    "    X = df_train_clean.drop(columns=['SurvivalTime', 'Censored', 'Gender', 'GeneticRisk', 'Id'])\n",
    "\n",
    "    y = df_train_clean['SurvivalTime']\n",
    "    c = df_train_clean['Censored'].values\n",
    "\n",
    "    X_train, X_test, y_train, y_test, c_train, c_test = train_test_split(X, y, c, test_size=0.2,\n",
    "                                                                         random_state=random.randint(0, 100))\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, c_train, c_test, df_test_filled\n",
    "\n",
    "#process_data_with_labels()"
   ],
   "id": "b506a5fb58f4473d",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T23:56:49.319124Z",
     "start_time": "2024-12-06T23:56:49.274577Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#usar o df_train_clean com imputation (data with labels)\n",
    "#usar o df_test_filled com imputation (data without labels)\n",
    "\n",
    "\n",
    "def process_data_without_labels():\n",
    "    train_path = './Datasets/train_data.csv'\n",
    "    test_path = \"./Datasets/test_data.csv\"\n",
    "\n",
    "    df_train_clean = pd.read_csv(train_path)\n",
    "    df_test_filled = pd.read_csv(test_path)\n",
    "\n",
    "    #aqui só queremos manter as rows em que SurvivalTime está missing (NaN)\n",
    "    df_train_clean = df_train_clean[df_train_clean['SurvivalTime'].isna()]\n",
    "\n",
    "    #agora temos que aplicar a imputation aos dados que estao missing\n",
    "    strategy = 'knn'\n",
    "    df_train_clean = apply_imputation(df_train_clean, 'GeneticRisk', strategy)\n",
    "    df_train_clean = apply_imputation(df_train_clean, 'ComorbidityIndex', strategy)\n",
    "    df_train_clean = apply_imputation(df_train_clean, 'TreatmentResponse', strategy)\n",
    "\n",
    "    msno.bar(df_train_clean)\n",
    "\n",
    "    df_test_filled = apply_imputation(df_test_filled, 'GeneticRisk', strategy)\n",
    "    df_test_filled = apply_imputation(df_test_filled, 'ComorbidityIndex', strategy)\n",
    "    df_test_filled = apply_imputation(df_test_filled, 'TreatmentResponse', strategy)\n",
    "\n",
    "    df_test_filled.drop('Id', axis=1, inplace=True)\n",
    "    df_test_filled = df_test_filled.drop(columns=['Gender', 'GeneticRisk'])\n",
    "\n",
    "    df_train_clean = df_train_clean[df_train_clean['Censored'] == 0]\n",
    "    X = df_train_clean.drop(columns=['SurvivalTime', 'Censored', 'Gender', 'GeneticRisk', 'Id'])\n",
    "\n",
    "    y = df_train_clean['SurvivalTime']\n",
    "    c = df_train_clean['Censored'].values\n",
    "\n",
    "    # Split the data into train and test sets --------> FEATURES, TARGETS\n",
    "    X_train, X_test, y_train, y_test, c_train, c_test = train_test_split(X, y, c, test_size=0.2,\n",
    "                                                                         random_state=42)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, c_train, c_test, df_test_filled\n",
    "\n",
    "\n",
    "process_data_without_labels()"
   ],
   "id": "e81d3a0084dccd3f",
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'imputer' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mUnboundLocalError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[192], line 39\u001B[0m\n\u001B[0;32m     34\u001B[0m     X_train, X_test, y_train, y_test, c_train, c_test \u001B[38;5;241m=\u001B[39m train_test_split(X, y, c, test_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.2\u001B[39m,\n\u001B[0;32m     35\u001B[0m                                                                         random_state\u001B[38;5;241m=\u001B[39mrandom\u001B[38;5;241m.\u001B[39mrandint(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m100\u001B[39m))\n\u001B[0;32m     37\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m X_train, X_test, y_train, y_test, c_train, c_test, df_test_filled\n\u001B[1;32m---> 39\u001B[0m \u001B[43mprocess_data_without_labels\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[192], line 16\u001B[0m, in \u001B[0;36mprocess_data_without_labels\u001B[1;34m()\u001B[0m\n\u001B[0;32m     14\u001B[0m df_train_clean \u001B[38;5;241m=\u001B[39m apply_imputation(df_train_clean, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mComorbidityIndex\u001B[39m\u001B[38;5;124m'\u001B[39m, strategy)\n\u001B[0;32m     15\u001B[0m df_train_clean \u001B[38;5;241m=\u001B[39m apply_imputation(df_train_clean, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTreatmentResponse\u001B[39m\u001B[38;5;124m'\u001B[39m, strategy)\n\u001B[1;32m---> 16\u001B[0m df_train_clean \u001B[38;5;241m=\u001B[39m \u001B[43mapply_imputation\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdf_train_clean\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mSurvivalTime\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m0\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     18\u001B[0m msno\u001B[38;5;241m.\u001B[39mbar(df_train_clean)\n\u001B[0;32m     20\u001B[0m df_test_filled \u001B[38;5;241m=\u001B[39m apply_imputation(df_test_filled, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mGeneticRisk\u001B[39m\u001B[38;5;124m'\u001B[39m, strategy)\n",
      "Cell \u001B[1;32mIn[159], line 14\u001B[0m, in \u001B[0;36mapply_imputation\u001B[1;34m(df, column, strategy)\u001B[0m\n\u001B[0;32m     11\u001B[0m     imputer \u001B[38;5;241m=\u001B[39m IterativeImputer(max_iter\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m60\u001B[39m)\n\u001B[0;32m     13\u001B[0m \u001B[38;5;66;03m#print(df[column])\u001B[39;00m\n\u001B[1;32m---> 14\u001B[0m df[column] \u001B[38;5;241m=\u001B[39m \u001B[43mimputer\u001B[49m\u001B[38;5;241m.\u001B[39mfit_transform(df[[column]])\n\u001B[0;32m     15\u001B[0m \u001B[38;5;66;03m#print(df[column])\u001B[39;00m\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m df\n",
      "\u001B[1;31mUnboundLocalError\u001B[0m: cannot access local variable 'imputer' where it is not associated with a value"
     ]
    }
   ],
   "execution_count": 192
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "bd0c2d6c1da3d396"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T13:39:59.049889Z",
     "start_time": "2024-12-07T13:39:59.042495Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_pipeline(lambda_value, is_ridge):    \n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('regressor', LinearRegression())\n",
    "    ])\n",
    "    \n",
    "    return pipeline"
   ],
   "id": "2745b4c313dc3b87",
   "outputs": [],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T13:40:57.758530Z",
     "start_time": "2024-12-07T13:40:56.984010Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Then, use the imputed data with labels to train a Linear Regression model. Compare with the baseline and with the model trained in Task 3.1.\n",
    "\n",
    "def run_model():\n",
    "    model = create_pipeline(0.01, False)\n",
    "    \n",
    "    strategy = 'iterative'\n",
    "\n",
    "    X_train, X_test, y_train, y_test, c_train, c_test, df_test_filled = process_data_with_labels(strategy)\n",
    "\n",
    "    # Cross-validated RMSE\n",
    "    cv_scores = cross_val_cMSE(model, X_train, y_train, c_train, cv=len(X_train) - 1)\n",
    "    cv_score = np.sqrt(np.mean(cv_scores))\n",
    "\n",
    "    # Baseline model training\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_submission = model.predict(df_test_filled)\n",
    "\n",
    "    # Preparing Submission File\n",
    "    y_submission_df = pd.DataFrame(y_submission, columns=['Target'])\n",
    "    y_submission_df['id'] = range(0, len(y_submission_df))\n",
    "    y_submission_df = y_submission_df[['id'] + [col for col in y_submission_df.columns if col != 'id']]\n",
    "    #y_submission_df.to_csv('cMSE-baseline-submission-00.csv', index=False)\n",
    "\n",
    "    error = root_mean_squared_error(y_pred, y_test)\n",
    "    test_cMSE = cMSE(y_pred, y_test.values, c_test)\n",
    "\n",
    "    return cv_score, error, test_cMSE, y_submission_df\n",
    "\n",
    "run_model()"
   ],
   "id": "4e3ba2db2c6c670c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.6690125084971619,\n",
       " 2.280279729759547,\n",
       " 5.199675645952273,\n",
       "     id    Target\n",
       " 0    0  6.349904\n",
       " 1    1  3.173198\n",
       " 2    2  4.895616\n",
       " 3    3  6.151944\n",
       " 4    4  3.160752\n",
       " ..  ..       ...\n",
       " 95  95  4.911129\n",
       " 96  96  4.030461\n",
       " 97  97  3.844447\n",
       " 98  98  4.920070\n",
       " 99  99  6.349215\n",
       " \n",
       " [100 rows x 2 columns])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T13:17:30.209324Z",
     "start_time": "2024-12-07T13:17:29.080354Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def find_best_imputation_strategy():\n",
    "    strategies = ['mean', 'median', 'most_frequent', 'knn', 'iterative']\n",
    "    iterations = 10\n",
    "    results = []\n",
    "    min_test_cMSE = 1000000\n",
    "    counter = 0\n",
    "\n",
    "    for strategy in strategies:\n",
    "        for i in range(iterations):\n",
    "            counter += 1\n",
    "            \n",
    "            model = Pipeline([\n",
    "                ('scaler', StandardScaler()),\n",
    "                ('regressor', LinearRegression())\n",
    "            ])\n",
    "\n",
    "            X_train, X_test, y_train, y_test, c_train, c_test, df_test_filled = process_data_with_labels(strategy)\n",
    "\n",
    "            # Cross-validated RMSE\n",
    "            cv_scores = cross_val_cMSE(model, X_train, y_train, c_train, cv=len(X_train) - 1)\n",
    "            cv_score = np.sqrt(np.mean(cv_scores))\n",
    "\n",
    "            # Baseline model training\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            # Predictions\n",
    "            y_pred = model.predict(X_test)\n",
    "            y_submission = model.predict(df_test_filled)\n",
    "\n",
    "            # Preparing Submission File\n",
    "            y_submission_df = pd.DataFrame(y_submission, columns=['Target'])\n",
    "            y_submission_df['id'] = range(0, len(y_submission_df))\n",
    "            y_submission_df = y_submission_df[['id'] + [col for col in y_submission_df.columns if col != 'id']]\n",
    "            #y_submission_df.to_csv('cMSE-baseline-submission-00.csv', index=False)\n",
    "\n",
    "            error = root_mean_squared_error(y_pred, y_test)\n",
    "            test_cMSE = cMSE(y_pred, y_test.values, c_test)\n",
    "\n",
    "            if test_cMSE < min_test_cMSE:\n",
    "                min_test_cMSE = test_cMSE\n",
    "                y_submission_df = pd.DataFrame(y_submission, columns=['Target'])\n",
    "                y_submission_df['id'] = range(0, len(y_submission_df))\n",
    "                y_submission_df = y_submission_df[['id'] + [col for col in y_submission_df.columns if col != 'id']]\n",
    "                y_submission_df.to_csv('cMSE-task4-submission-00.csv', index=False)\n",
    "\n",
    "            result = (\n",
    "                f\"Imputation Strategy: {strategy}\\n\"\n",
    "                f\"Cross-validated RMSE: {cv_score:.4f}\\n\"\n",
    "                f\"Mean Squared Error (MSE): {error:.6f}\\n\"\n",
    "                f\"Test cMSE Loss: {test_cMSE:.4f}\\n\"\n",
    "            )\n",
    "\n",
    "            results.append((test_cMSE, result, y_submission))\n",
    "\n",
    "    best_result = find_best_result(results)\n",
    "    print(\"Best result out of\", counter, \"iterations\")\n",
    "    print(best_result[1])\n",
    "    \n",
    "find_best_imputation_strategy()"
   ],
   "id": "b8f3d09c05096015",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names seen at fit time, yet now missing:\n- GeneticRisk\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[41], line 59\u001B[0m\n\u001B[0;32m     56\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBest result out of\u001B[39m\u001B[38;5;124m\"\u001B[39m, counter, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124miterations\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     57\u001B[0m     \u001B[38;5;28mprint\u001B[39m(best_result[\u001B[38;5;241m1\u001B[39m])\n\u001B[1;32m---> 59\u001B[0m \u001B[43mfind_best_imputation_strategy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[41], line 28\u001B[0m, in \u001B[0;36mfind_best_imputation_strategy\u001B[1;34m()\u001B[0m\n\u001B[0;32m     26\u001B[0m \u001B[38;5;66;03m# Predictions\u001B[39;00m\n\u001B[0;32m     27\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mpredict(X_test)\n\u001B[1;32m---> 28\u001B[0m y_submission \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdf_test_filled\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     30\u001B[0m \u001B[38;5;66;03m# Preparing Submission File\u001B[39;00m\n\u001B[0;32m     31\u001B[0m y_submission_df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(y_submission, columns\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTarget\u001B[39m\u001B[38;5;124m'\u001B[39m])\n",
      "File \u001B[1;32mC:\\Python312\\Lib\\site-packages\\sklearn\\pipeline.py:600\u001B[0m, in \u001B[0;36mPipeline.predict\u001B[1;34m(self, X, **params)\u001B[0m\n\u001B[0;32m    598\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _routing_enabled():\n\u001B[0;32m    599\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m _, name, transform \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iter(with_final\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[1;32m--> 600\u001B[0m         Xt \u001B[38;5;241m=\u001B[39m \u001B[43mtransform\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mXt\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    601\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msteps[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m][\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39mpredict(Xt, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams)\n\u001B[0;32m    603\u001B[0m \u001B[38;5;66;03m# metadata routing enabled\u001B[39;00m\n",
      "File \u001B[1;32mC:\\Python312\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:316\u001B[0m, in \u001B[0;36m_wrap_method_output.<locals>.wrapped\u001B[1;34m(self, X, *args, **kwargs)\u001B[0m\n\u001B[0;32m    314\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(f)\n\u001B[0;32m    315\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapped\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m--> 316\u001B[0m     data_to_wrap \u001B[38;5;241m=\u001B[39m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    317\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data_to_wrap, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[0;32m    318\u001B[0m         \u001B[38;5;66;03m# only wrap the first output for cross decomposition\u001B[39;00m\n\u001B[0;32m    319\u001B[0m         return_tuple \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    320\u001B[0m             _wrap_data_with_container(method, data_to_wrap[\u001B[38;5;241m0\u001B[39m], X, \u001B[38;5;28mself\u001B[39m),\n\u001B[0;32m    321\u001B[0m             \u001B[38;5;241m*\u001B[39mdata_to_wrap[\u001B[38;5;241m1\u001B[39m:],\n\u001B[0;32m    322\u001B[0m         )\n",
      "File \u001B[1;32mC:\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:1045\u001B[0m, in \u001B[0;36mStandardScaler.transform\u001B[1;34m(self, X, copy)\u001B[0m\n\u001B[0;32m   1042\u001B[0m check_is_fitted(\u001B[38;5;28mself\u001B[39m)\n\u001B[0;32m   1044\u001B[0m copy \u001B[38;5;241m=\u001B[39m copy \u001B[38;5;28;01mif\u001B[39;00m copy \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcopy\n\u001B[1;32m-> 1045\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_data\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1046\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1047\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m   1048\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcsr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1049\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1050\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mFLOAT_DTYPES\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1051\u001B[0m \u001B[43m    \u001B[49m\u001B[43mforce_writeable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m   1052\u001B[0m \u001B[43m    \u001B[49m\u001B[43mforce_all_finite\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mallow-nan\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1053\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1055\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m sparse\u001B[38;5;241m.\u001B[39missparse(X):\n\u001B[0;32m   1056\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwith_mean:\n",
      "File \u001B[1;32mC:\\Python312\\Lib\\site-packages\\sklearn\\base.py:608\u001B[0m, in \u001B[0;36mBaseEstimator._validate_data\u001B[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001B[0m\n\u001B[0;32m    537\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_validate_data\u001B[39m(\n\u001B[0;32m    538\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    539\u001B[0m     X\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mno_validation\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    544\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcheck_params,\n\u001B[0;32m    545\u001B[0m ):\n\u001B[0;32m    546\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001B[39;00m\n\u001B[0;32m    547\u001B[0m \n\u001B[0;32m    548\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    606\u001B[0m \u001B[38;5;124;03m        validated.\u001B[39;00m\n\u001B[0;32m    607\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 608\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_check_feature_names\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreset\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    610\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m y \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_tags()[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrequires_y\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n\u001B[0;32m    611\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    612\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThis \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m estimator \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    613\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrequires y to be passed, but the target y is None.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    614\u001B[0m         )\n",
      "File \u001B[1;32mC:\\Python312\\Lib\\site-packages\\sklearn\\base.py:535\u001B[0m, in \u001B[0;36mBaseEstimator._check_feature_names\u001B[1;34m(self, X, reset)\u001B[0m\n\u001B[0;32m    530\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m missing_names \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m unexpected_names:\n\u001B[0;32m    531\u001B[0m     message \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    532\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFeature names must be in the same order as they were in fit.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    533\u001B[0m     )\n\u001B[1;32m--> 535\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(message)\n",
      "\u001B[1;31mValueError\u001B[0m: The feature names should match those that were passed during fit.\nFeature names seen at fit time, yet now missing:\n- GeneticRisk\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T15:36:44.110970Z",
     "start_time": "2024-12-07T15:36:41.315640Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def run_iterations():\n",
    "    iterations = 10\n",
    "    results = []\n",
    "    min_test_cMSE = 1000000\n",
    "\n",
    "    for i in range(iterations):\n",
    "        cv_score, error, test_cMSE, y_submission = run_model()\n",
    "\n",
    "        if test_cMSE < min_test_cMSE:\n",
    "            min_test_cMSE = test_cMSE\n",
    "            y_submission_df = pd.DataFrame(y_submission, columns=['Target'])\n",
    "            y_submission_df['id'] = range(0, len(y_submission_df))\n",
    "            y_submission_df = y_submission_df[['id'] + [col for col in y_submission_df.columns if col != 'id']]\n",
    "            y_submission_df.to_csv('cMSE-task4-submission-00.csv', index=False)\n",
    "\n",
    "        result = (\n",
    "            f\"Cross-validated RMSE: {cv_score:.4f}\\n\"\n",
    "            f\"Mean Squared Error (MSE): {error:.6f}\\n\"\n",
    "            f\"Test cMSE Loss: {test_cMSE:.4f}\\n\"\n",
    "        )\n",
    "\n",
    "        results.append((test_cMSE, result, y_submission))\n",
    "\n",
    "    best_result = find_best_result(results)\n",
    "    print(best_result[1])\n",
    "    best_result[2].to_csv('cMSE-task4-submission-00.csv', index=False)\n",
    "\n",
    "run_iterations()"
   ],
   "id": "45687275dea6065f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated RMSE: 1.9003\n",
      "Mean Squared Error (MSE): 1.533002\n",
      "Test cMSE Loss: 2.3501\n",
      "\n"
     ]
    }
   ],
   "execution_count": 72
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T11:47:23.834871Z",
     "start_time": "2024-12-07T11:47:23.827787Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def find_best_result(results):\n",
    "    best_model_run = None\n",
    "\n",
    "    for test_cMSE, result, predictions in results:\n",
    "        if best_model_run is None or test_cMSE < best_model_run[0]:\n",
    "            best_model_run = (test_cMSE, result, predictions)\n",
    "\n",
    "    return best_model_run"
   ],
   "id": "44d3302993cae1e8",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Melhor imputation da task 3.1: \n",
    "# Testar com labels na data e sem labels - TODO\n",
    "# Treinar modelo de regressão linear com os dados imputados com labels - TODO\n",
    "# Comparar com o baseline model e com o modelo treinado na task 3.1. - TODO"
   ],
   "id": "ef13973fd2140508"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
